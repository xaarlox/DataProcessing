# Генератор енергетичних звітів
Цей проєкт призначений для автоматичної генерації випадкових, але контекстуально правдоподібних текстових даних, що імітують корпоративні звіти енергетичних компаній (на прикладі інтегрованого звіту ДТЕК).

## Постановка задачі
Реалізуйте генерацію випадкових текстових даних для опису енергетичних проєктів або звітів, що імітують реальні сценарії з використанням Markovify. Оцініть якість згенерованих звітів для тестування алгоритмів обробки текстових даних.

## Аналіз проблеми та підхід до рішення
Для тестування NLP-алгоритмів необхідні великі обсяги галузевих даних. Використання ланцюгів Маркова дозволяє на основі одного реального документа згенерувати нескінченну кількість унікальних текстів, які зберігають галузеву термінологію, синтаксичну структуру та стиль оригінального документа.

**Етапи реалізації**:
1. *Парсинг*: Зчитування "сирого" тексту з реального PDF-звіту.
2. *Чистка*: Видалення артефактів PDF-форматування (маркери списків, розірвані перенесенням слова, візуальна розрядка тексту) за допомогою регулярних виразів.
3. *Генерація*: Навчання моделі Маркова та створення нових абзаців.
4. *Оцінка*: Програмний підрахунок лексичного різноманіття та рівня унікальності тексту.

## Використані бібліотеки
+ **PyPDF2** - для екстракції текстових даних із багатосторінкових PDF-документів.
+ **markovify** - легка бібліотека для побудови ланцюгів Маркова. (Використано параметр `state_size=2`, що дозволяє досягти оптимального балансу між зв'язністю речень та унікального тексту.)
+ **re** - ключовий інструмент для підготовки датасету. Забезпечує вирішення специфічних проблем форматування.
+ **textwrap** - стандартна бібліотека Python для форматування виводу в консоль (запобігає надто довгим рядкам).

## Особливості реалізації
1. **Очищення даних**

   PDF-файли часто містять візуальне форматування, яке ламає логіку NLP-моделей. У функції `extract_and_clean_pdf` реалізовано:
   - Видалення спецсимволів маркованих списків;
   - Склеювання слів, розірваних дефісами та перенесеннями на новий рядок (наприклад, "транс - формації" -> "трансформації");
   - Виправлення трекінгу/розрядки тексту (наприклад, "Д Т Е К" -> "ДТЕК", "д і л я н ц і" -> "ділянці");
   - Виправлення відірваних великих літер (наприклад, "Г рупи" -> "Групи").

2. **Генерація тексту**

   Генерація відбувається поабзацно. Кожен абзац складається з 4 речень (довжиною до 200 символів), згенерованих методом `make_short_sentence`.

3. **Оцінка якості**

   У проєкті реалізовано автоматичну оцінку якості звіту (`evaluate_generation_quality`), що є критично важливим для тестування NLP-алгоритмів:
   * **Лексичне різноманіття (TTR)**: Показує багатство словникового запасу. Нормальний показник: 0.4 - 0.6. Захищає від зациклення моделі.
   * **Рівень плагіату**: Визначає відсоток речень, які 100% були дослівно скопійовані з оригіналу. Допомігає налаштувати параметр `state_size`.

## Результат виконання

<p align="center">
  <img width="700" height="500" alt="image" src="https://github.com/user-attachments/assets/1b42d4d1-c2fd-4e33-9d7b-684314332926" />
</p>

З точки зору людини-читача, згенерований текст сприймається важкувато. Якщо читати його швидко, він здається абсолютно логічним звітом, але при вдумливому читанні семантичний сенс часто губиться або стає абсурдним.

Це пов'язано з математичною природою алгоритму Маркова: він не розуміє глобального контексту абзацу, а лише передбачає наступне слово на основі двох-трьох попередніх (N-грам). Через це ми отримуємо ефект "корпоративної шизофазії": граматично та синтаксично слова узгоджені ідеально (відмінки, числа, роди), але логічно речення може початися з розповіді про будівництво вітроелектростанції, а закінчитися тарифами на диспетчерське управління чи екологічними ініціативами.

**Загальний висновок**:

Для людського читання такий текст не несе змістовної цінності. Проте, зі своїм головним завданням - створенням реалістичного "шумового" звіту для тестування NLP-алгоритмів - програма справляється ідеально. Для навчання парсерів, тестування повнотекстового пошуку або алгоримтів вилучення сутностей машині не потрібен глибокий філософський сенс; їй потрібна правильна структура речень, наявність чисел, абревіатур та галузевих термінів.
